{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case that FrImCla is not installed in your system, the first task consist in installing using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: frimcla in /home/magarcd/Escritorio/frimcla (0.0.529)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python2.7/dist-packages (from frimcla) (3.4.1.15)\n",
      "Requirement already satisfied: mahotas in /usr/local/lib/python2.7/dist-packages (from frimcla) (1.4.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (from frimcla) (0.23.0)\n",
      "Requirement already satisfied: imutils in /usr/local/lib/python2.7/dist-packages (from frimcla) (0.4.6)\n",
      "Requirement already satisfied: scikit-image in /usr/lib/python2.7/dist-packages (from frimcla) (0.13.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python2.7/dist-packages (from frimcla) (0.8.2)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python2.7/dist-packages (from frimcla) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python2.7/dist-packages (from frimcla) (2.0.2)\n",
      "Requirement already satisfied: guppy in /usr/local/lib/python2.7/dist-packages (from frimcla) (0.1.10)\n",
      "Requirement already satisfied: Keras==2.1.6 in /usr/local/lib/python2.7/dist-packages (from frimcla) (2.1.6)\n",
      "Requirement already satisfied: commentjson in /usr/local/lib/python2.7/dist-packages (from frimcla) (0.6)\n",
      "Requirement already satisfied: theano in /usr/local/lib/python2.7/dist-packages (from frimcla) (1.0.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from frimcla) (2.7.1)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python2.7/dist-packages (from frimcla) (3.2)\n",
      "Requirement already satisfied: numpy in /usr/lib/python2.7/dist-packages (from frimcla) (1.13.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages/scikit_learn-0.19.1-py2.7-linux-x86_64.egg (from frimcla) (0.19.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/lib/python2.7/dist-packages (from pandas->frimcla) (2018.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/lib/python2.7/dist-packages (from pandas->frimcla) (2.6.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/lib/python2.7/dist-packages (from scikit-image->frimcla) (0.5.1)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/lib/python2.7/dist-packages (from scikit-image->frimcla) (1.11)\n",
      "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image->frimcla) (5.1.0)\n",
      "Requirement already satisfied: six>=1.7.3 in /usr/local/lib/python2.7/dist-packages (from scikit-image->frimcla) (1.11.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (1.12.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (2.0.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (3.5.2.post1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (0.2.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (0.31.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (0.2.1)\n",
      "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (1.0.post1)\n",
      "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (1.1.6)\n",
      "Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (1.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow->frimcla) (0.6.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python2.7/dist-packages (from matplotlib->frimcla) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /usr/lib/python2.7/dist-packages (from matplotlib->frimcla) (2.2.0)\n",
      "Requirement already satisfied: subprocess32 in /usr/lib/python2.7/dist-packages (from matplotlib->frimcla) (3.2.7)\n",
      "Requirement already satisfied: functools32 in /usr/local/lib/python2.7/dist-packages (from matplotlib->frimcla) (3.2.3.post2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from Keras==2.1.6->frimcla) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages/scipy-1.1.0-py2.7-linux-x86_64.egg (from Keras==2.1.6->frimcla) (1.1.0)\n",
      "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow->frimcla) (3.2.0)\n",
      "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow->frimcla) (1.0.2)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow->frimcla) (4.0.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.4.0->tensorflow->frimcla) (39.2.0)\n",
      "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow->frimcla) (1.5.0)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow->frimcla) (0.9999999)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow->frimcla) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow->frimcla) (2.6.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install frimcla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we have to import all the classes that we will need to be able to use our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scikit_learn-0.19.1-py2.7-linux-x86_64.egg/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xc but this version of numpy is 0xb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xc but this version of numpy is 0xb"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "from frimcla.utils.conf import Conf\n",
    "from imutils import paths\n",
    "from __future__ import print_function\n",
    "from frimcla.index_features import generateFeatures\n",
    "from frimcla.StatisticalComparison import statisticalComparison, majorityVoting\n",
    "from frimcla.train import train\n",
    "from frimcla.prediction import prediction,predictionEnsemble\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://drive.google.com/uc?id=1nMhMINs75FEIW2bAgmSbW1OqUV1Cqs3b&export=download&authuser=0\" -O DogCat.zip\n",
    "!unzip DogCat.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the dataset path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we have to know the path which we have our dataset. The dataset must have a folder for each class that we want to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"DogCat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we decide the feature extractor models that we are going to use with our dataset. These models will extract the most important points of the images. Then we save the points and with the classifier models that we will choose after this, we will classify the images with the classes of the dataset. Each feature extractor model has a different way to collect the most important points and for this reason we have to compare the models, because there is not a model that always fits better with the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureExtractors = [[\"resnet\", \"False\"],[\"vgg16\", \"False\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the feature extractor models we can execute the algorithm that collect the features of the dataset for each model. The only thing that we have to do is indicate the paths of the dataset and the output and the models that we want to use for the study. The verbose parameter is to indicate whether we want to appear information about the execution on console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generateFeatures(\"./\", 32, datasetPath, featureExtractors, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm will create a set of files that contains the features of the images. Each file corresponds to a model of those indicated above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have stored the features of the images, we have to choose the clasiffication models that we are going to use for the dataset. All these classifiers will be used for each feature extractor model to know which is the performance of every combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelClassifiers = [ \"MLP\",\"SVM\",\"KNN\", \"LogisticRegression\", \"GradientBoost\", \"RandomForest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the classifiers chosen, now that we have to do is to carry out a statistical analysis. The analysis studies and compares every combination. Once the analysis has compared all the combinations gives us the best combination of feature extractor model and classifier model and all the combinations that have not significant differencies with the best result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measures and ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to select a performance measure to know which is the performance of the algorithm. In this case, there are five different measures (accuracy, recall, precision, auroc and f1). The user have to select only one of the five measures. Accuracy is the default measure.\n",
    "\n",
    "To improve the performance, the framework uses an ensemble technique called majority voting. This technique uses all the models generated to predict the class of the image. The framework only saves the models that have a certain percentage of the measure chosen by the user. Then these models will be trained to classify the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "majorityVoting(\"./\", datasetPath, featureExtractors, modelClassifiers, measure, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to train the models. In this step, all the models that have been selected will be trained. But only models with more than 56% of the measure chosen previously. Thus, the framework prevents models with bad results from worsening the prediction. In this case we do not split the dataset in test and train data, we need all the images to train and improve the results of the model. \n",
    "\n",
    "In this function FrImCla asks the user if he wants a web application or not (Y if the user wants the webapp). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "train(\"./\", datasetPath, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the model trained, we can predict the class of the new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the models trained we can predict the classes of our images. For this task, we have developed another algorithm to use the models. This execution will give us the predicted class of the image that we choose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = datasetPath[datasetPath.rfind(\"/\"):]\n",
    "imagePaths = list(paths.list_images(datasetPath))\n",
    "\n",
    "with open(\"./\" + datasetName +'/ConfModel.json') as data:\n",
    "    datos = json.load(data)\n",
    "\n",
    "extractors = datos[\"featureExtractors\"]\n",
    "classifiers = [\"GradientBoost\",\"RandomForest\", \"SVM\",\"KNN\",\"LogisticRegression\", \"MLP\"]\n",
    "\n",
    "imagePaths = list(paths.list_images(\"/home/magarcd/Escritorio/dataset/MiasRecortadasTEST\"))\n",
    "predictionEnsemble(featureExtractors, modelClassifiers, imagePaths, \"./\", datasetName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
